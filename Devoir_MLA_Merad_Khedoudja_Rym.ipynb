{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devoir Machine Learning Avancé \n",
    "\n",
    "**Merad Khedoudja Rym**\n",
    "\n",
    "\n",
    "**IA Cheffe de projet IA sprécialité Data Science**\n",
    "**M2 E-learning**\n",
    "\n",
    "Ce devoir a pour but de prédir les "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des bibliothèques communes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ArithmeticError\\n# Charger les données depuis un fichier CSV\\n# Charger les données depuis un fichier CSV avec le paramètre quotechar\\ndonnees = pd.read_csv(\\'Data/USA_Housing.csv\\', quotechar=\\'\"\\')\\n\\n# Afficher les premières lignes des données pour vérifier\\nprint(donnees.head())\\n\\n# Séparer les features (X) et la variable cible (y)\\nX = donnees[[\\'Avg. Area Income\\', \\'Avg. Area House Age\\', \\'Avg. Area Number of Rooms\\', \\'Avg. Area Number of Bedrooms\\', \\'Area Population\\']]\\ny = donnees[\\'Price\\']\\n\\n# Ajouter une colonne de 1 pour le terme constant\\nX[\\'Ones\\'] = 1\\n\\n# Initialiser les paramètres\\ntheta = np.random.randn(X.shape[1], 1)\\n\\n# Nombre d\\'itérations et taux d\\'apprentissage\\nn_iterations = 1000\\nalpha = 0.01\\n\\n# Gradient Descent\\nfor i in range(0, n_iterations):\\n    theta = theta - alpha * (1/len(y)) * X.T.dot(X.dot(theta) - y.values.reshape(-1, 1))\\n\\n# Afficher les paramètres finaux\\nprint(\\'Paramètres finaux:\\')\\nprint(theta)\\n\\n# Prédiction avec les paramètres finaux\\npredictions = X.dot(theta)\\n\\n# Tracer les prédictions par rapport aux vraies valeurs\\nplt.scatter(y, predictions)\\nplt.xlabel(\\'Vraies Valeurs\\')\\nplt.ylabel(\\'Prédictions\\')\\nplt.title(\\'Prédictions vs Vraies Valeurs\\')\\nplt.show()\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\"\"\"ArithmeticError\n",
    "# Charger les données depuis un fichier CSV\n",
    "# Charger les données depuis un fichier CSV avec le paramètre quotechar\n",
    "donnees = pd.read_csv('Data/USA_Housing.csv', quotechar='\"')\n",
    "\n",
    "# Afficher les premières lignes des données pour vérifier\n",
    "print(donnees.head())\n",
    "\n",
    "# Séparer les features (X) et la variable cible (y)\n",
    "X = donnees[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms', 'Avg. Area Number of Bedrooms', 'Area Population']]\n",
    "y = donnees['Price']\n",
    "\n",
    "# Ajouter une colonne de 1 pour le terme constant\n",
    "X['Ones'] = 1\n",
    "\n",
    "# Initialiser les paramètres\n",
    "theta = np.random.randn(X.shape[1], 1)\n",
    "\n",
    "# Nombre d'itérations et taux d'apprentissage\n",
    "n_iterations = 1000\n",
    "alpha = 0.01\n",
    "\n",
    "# Gradient Descent\n",
    "for i in range(0, n_iterations):\n",
    "    theta = theta - alpha * (1/len(y)) * X.T.dot(X.dot(theta) - y.values.reshape(-1, 1))\n",
    "\n",
    "# Afficher les paramètres finaux\n",
    "print('Paramètres finaux:')\n",
    "print(theta)\n",
    "\n",
    "# Prédiction avec les paramètres finaux\n",
    "predictions = X.dot(theta)\n",
    "\n",
    "# Tracer les prédictions par rapport aux vraies valeurs\n",
    "plt.scatter(y, predictions)\n",
    "plt.xlabel('Vraies Valeurs')\n",
    "plt.ylabel('Prédictions')\n",
    "plt.title('Prédictions vs Vraies Valeurs')\n",
    "plt.show()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données et leur nettoyage \n",
    "\n",
    "Le nettoyage fut un long combat mais qui a bien payé! \n",
    "\n",
    "Le csv présentait plusieurs anomalies: notament la presence deux ç\"couches\" de guillemets (\" \" \" \")\n",
    "Le nettoyage s'est effectué en deux temps en lever couche par couche les guillemets mais il existe plusieurs méthodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Avg. Area Income  Avg. Area House Age  \\\n",
      "0  79545.45857431678,5.682861321615587,7.00918814...                  NaN   \n",
      "1                           Laurabury, NE 37010-5101                  NaN   \n",
      "2  79248.64245482568,6.0028998082752425,6.7308210...                  NaN   \n",
      "3                            Lake Kathleen, CA 48958                  NaN   \n",
      "4  61287.067178656784,5.865889840310001,8.5127274...                  NaN   \n",
      "\n",
      "   Avg. Area Number of Rooms  Avg. Area Number of Bedrooms  Area Population  \\\n",
      "0                        NaN                           NaN              NaN   \n",
      "1                        NaN                           NaN              NaN   \n",
      "2                        NaN                           NaN              NaN   \n",
      "3                        NaN                           NaN              NaN   \n",
      "4                        NaN                           NaN              NaN   \n",
      "\n",
      "   Price  Address  \n",
      "0    NaN      NaN  \n",
      "1    NaN      NaN  \n",
      "2    NaN      NaN  \n",
      "3    NaN      NaN  \n",
      "4    NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "# Lecture du csv initial USA_Housing.csv present dans le repertoire Data\n",
    "with open('Data/USA_Housing.csv', 'r') as file:\n",
    "    contenu = file.read()\n",
    "\n",
    "# Supprimer les guillemets doubles ici nous parlons de la première couche \n",
    "contenu = contenu.replace('\"\"', '')\n",
    "\n",
    "# Écrire le contenu modifié dans un nouveau fichier CSV\n",
    "with open('Data/clean_data.csv', 'w') as file:\n",
    "    file.write(contenu)\n",
    "\n",
    "# Charger les données depuis le nouveau fichier CSV avec pandas\n",
    "donnees = pd.read_csv('Data/clean_data.csv')\n",
    "\n",
    "# Afficher les premières lignes des données pour vérifier\n",
    "print(donnees.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 7 fields in line 30, saw 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rymkm\\Desktop\\Cours 2023 - 2024\\IA School M2\\S1\\S1.1\\Machine learning\\Merad Khedoudja Rym Projet House Pricing MLA\\Devoir_MLA_Merad_Khedoudja_Rym.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rymkm/Desktop/Cours%202023%20-%202024/IA%20School%20M2/S1/S1.1/Machine%20learning/Merad%20Khedoudja%20Rym%20Projet%20House%20Pricing%20MLA/Devoir_MLA_Merad_Khedoudja_Rym.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     file\u001b[39m.\u001b[39mwrite(contenu_sans_guillemets)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rymkm/Desktop/Cours%202023%20-%202024/IA%20School%20M2/S1/S1.1/Machine%20learning/Merad%20Khedoudja%20Rym%20Projet%20House%20Pricing%20MLA/Devoir_MLA_Merad_Khedoudja_Rym.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Charger les données depuis le nouveau fichier CSV avec pandas\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rymkm/Desktop/Cours%202023%20-%202024/IA%20School%20M2/S1/S1.1/Machine%20learning/Merad%20Khedoudja%20Rym%20Projet%20House%20Pricing%20MLA/Devoir_MLA_Merad_Khedoudja_Rym.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m donnees \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mData/data.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rymkm\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rymkm\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rymkm\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\rymkm\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\rymkm\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1779\u001b[0m         nrows\n\u001b[0;32m   1780\u001b[0m     )\n\u001b[0;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\rymkm\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 230\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    231\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mc:\\Users\\rymkm\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\rymkm\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\rymkm\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\rymkm\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 7 fields in line 30, saw 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "donnees = pd.read_csv('Data/clean_data.csv', quotechar='\"', skiprows=1)\n",
    "# Écrire le contenu modifié dans un nouveau fichier CSV\n",
    "with open('Data/data.csv', 'w') as file:\n",
    "    file.write(contenu_sans_guillemets)\n",
    "\n",
    "# Charger les données depuis le nouveau fichier CSV avec pandas\n",
    "donnees = pd.read_csv('Data/data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
